MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  #Downloading: "https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl" to /root/.torch/models/R-101.pkl
  #/opt/conda/lib/python3.6/site-packages/torch/hub.py:436: UserWarning: torch.hub._download_url_to_file has been renamed to            torch.hub.download_url_to_file to be a public API,            _download_url_to_file will be removed in after 1.3 release
  # WEIGHT: "FCOS_imprv_R_101_FPN_2x.pth" # "/u/50/orrea1/unix/Documents/FCOS/FCOS_R_101_FPN_2x.pth"
  RPN_ONLY: True
  FCOS_ON: True
  RETINANET_ON: False
  BACKBONE:
    CONV_BODY: "R-101-FPN-RETINANET"
    #CONV_BODY: "R-50-FPN-RETINANET"  
  #DEVICE: "cpu"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 32
  RETINANET:
    USE_C5: False # FCOS uses P5 instead of C5
    NUM_CLASSES: 7
  FCOS:
    NORM_REG_TARGETS: True
    CENTERNESS_ON_REG: True
    CENTER_SAMPLING_RADIUS: 1.5
    IOU_LOSS_TYPE: "giou"
    NUM_CLASSES: 7
    FPN_STRIDES: [8, 12, 16, 24, 32] #[8, 16, 32, 64, 128] # [4, 8, 162, 64, 128] [2, 4, 8, 16, 32] #
    NUM_CONVS: 4
  RPN:
    BATCH_SIZE_PER_IMAGE: 512
    ANCHOR_SIZES: (8, 12, 16, 32) #(32, 64, 128, 256, 512) # (16, 32, 64, 128, 256, 512)
    MIN_SIZE: 15
  ROI_BOX_HEAD:
    NUM_CLASSES: 7
DATASETS:
  TRAIN: ("voc_frame_train",) #("voc_man_shadows_train",)
  TEST: ("voc_man_shadows_frame_test",) #("voc_person8_train",)
INPUT:
  #MIN_SIZE_RANGE_TRAIN: (800, 1024) #(224, 800)
  MIN_SIZE_TRAIN: (3072,)
  MAX_SIZE_TRAIN: 3072
  MIN_SIZE_TEST: 4096 #1280
  MAX_SIZE_TEST: 4096 #1280
DATALOADER:
  SIZE_DIVISIBILITY: 1 #32
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
TEST:
  IMS_PER_BATCH: 1
  DETECTIONS_PER_IMG: 40
SOLVER:
  CHECKPOINT_PERIOD: 500
  BASE_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (120000, 160000)
  # MAX_ITER: 180000
  #STEPS: (6000, 8000)
  MAX_ITER: 7000
  # MAX_ITER: 90000
  IMS_PER_BATCH: 1 #  3
  # IMS_PER_BATCH: 16
  WARMUP_METHOD: "constant"
  WARMUP_ITERS: 2
OUTPUT_DIR: "/data/mnist/data_drive/fcos_trained_models/fcos_R_101_FPN_2x_person8_man_shadows"

# 0.6732 (0.7370)
# 0.6501 (0.6625)
# 0.6378 (0.6500)
# 0.6378 (0.6500)
# 0.6380 (0.6439)

#("voc_person8_train",)

# drone_train.sh --skip-test \

#import torch
#model = torch.load('trained_models/fcos_R_101_FPN_2x/inference/coco_drone_test/predictions.pth')
# /data/mnist/data_drive/fcos_trained_models/fcos_R_101_FPN_2x_person8/inference/voc_person8_train/predictions.pth

# import torch
#path = '/data/mnist/data_drive/fcos_trained_models/fcos_R_101_FPN_2x_person8/inference/voc_person8_train/predictions.pth'
# model = torch.load(path)

# import torch
# path = '/data/mnist/data_drive/fcos_trained_models/fcos_R_101_FPN_2x_person8_man_shadows/inference/voc_man_shadows_frame_test/predictions.pth'
# model = torch.load(path)
# print(model[0].bbox)

#def xyxy_to_xywh(xyxy_box):
#       xmin, ymin, xmax, ymax = xyxy_box
#       TO_REMOVE = 1
#       xywh_box = (xmin, ymin, xmax - xmin + TO_REMOVE, ymax - ymin + TO_REMOVE)
#       return xywh_box

#for x in model[0].bbox.tolist():
       #print(xyxy_to_xywh(x))